rates |>
ggplot(mapping = aes(x = sed_rate,
group = file_name)) +
geom_line(stat = "density", alpha=0.1, show.legend = FALSE)  +
facet_grid(~segment,
scales = 'free') +
scale_color_viridis(option = 'plasma', discrete = TRUE)
dev.off()
pdf(file = 'rates.pdf', width = 6.5,
height = 3)
rates |>
ggplot(mapping = aes(x = sed_rate,
group = file_name)) +
geom_line(stat = "density", alpha=0.01, show.legend = FALSE)  +
facet_grid(~segment,
scales = 'free') +
scale_color_viridis(option = 'plasma', discrete = TRUE)
dev.off()
rates |>
ggplot(mapping = aes(x = sed_rate,
group = file_name)) +
geom_line(stat = "density", alpha=0.01, show.legend = FALSE)  +
facet_grid(~segment,
scales = 'free_xy') +
scale_color_viridis(option = 'plasma', discrete = TRUE)
pdf(file = 'rates.pdf', width = 6.5,
height = 3)
rates |>
ggplot(mapping = aes(x = sed_rate,
group = file_name)) +
geom_line(stat = "density", alpha=0.01, show.legend = FALSE)  +
facet_grid(~segment,
scales = 'free') +
scale_color_viridis(option = 'plasma', discrete = TRUE)
dev.off()
rates |>
ggplot(mapping = aes(x = sed_rate,
group = file_name)) +
geom_line(stat = "density", alpha=0.01, show.legend = FALSE)  +
facet_grid(segment~.,
scales = 'free') +
scale_color_viridis(option = 'plasma', discrete = TRUE)
pdf(file = 'rates.pdf', width = 6.5,
height = 3)
rates |>
ggplot(mapping = aes(x = sed_rate,
group = file_name)) +
geom_line(stat = "density", alpha=0.01, show.legend = FALSE)  +
facet_grid(segment~.,
scales = 'free') +
scale_color_viridis(option = 'plasma', discrete = TRUE)
dev.off()
rm(list = ls())
# load required libraries -----------------------------------------------------
library(parallel)
library(tidyverse)
# set up the models to test ---------------------------------------------------
iterations <- 1000 # test each set of parameters 1000 times
index    <- rep(1:iterations) # add iterations
# put it in a data frame
tests    <- data.frame(i = index)
# set up for parallel processing ----------------------------------------------
numCores <- detectCores() - 2 # leave one core to run the computer
cl <- makeCluster(numCores) # make a cluster running R in parallel
# load the testing data on each cluster ---------------------------------------
clusterEvalQ(cl = cl, {
library(astroBayes)
library(tidyverse)
# load required data
cyclostrat        <- read.csv(file = './data/CIP2/cyclostratigraphic_record.csv')
tuning_frequency  <- read.csv(file = './data/CIP2/tuning_frequency.csv')
true_data         <- read.csv(file = './data/CIP2/true_age.csv')
segment_edges     <- read.csv(file = './data/CIP2/segment_edges.csv')
geochron_data     <- read.csv(file = './data/CIP2/radioisotopic_dates.csv')
}
)
# load required libraries -----------------------------------------------------
library(parallel)
library(tidyverse)
# set up the models to test ---------------------------------------------------
iterations <- 1000 # test each set of parameters 1000 times
index    <- rep(1:iterations) # add iterations
# put it in a data frame
tests    <- data.frame(i = index)
# set up for parallel processing ----------------------------------------------
numCores <- detectCores() - 2 # leave one core to run the computer
cl <- makeCluster(numCores) # make a cluster running R in parallel
numCores
cl <- makeCluster(numCores) # make a cluster running R in parallel
# load the testing data on each cluster ---------------------------------------
clusterEvalQ(cl = cl, {
library(astroBayes)
library(tidyverse)
# load required data
cyclostrat        <- read.csv(file = './data/CIP2/cyclostratigraphic_record.csv')
tuning_frequency  <- read.csv(file = './data/CIP2/tuning_frequency.csv')
true_data         <- read.csv(file = './data/CIP2/true_age.csv')
segment_edges     <- read.csv(file = './data/CIP2/segment_edges.csv')
geochron_data     <- read.csv(file = './data/CIP2/radioisotopic_dates.csv')
}
)
# load required data
cyclostrat        <- read.csv(file = './data/CIP2/cyclostratigraphic_record.csv')
segment_edges     <- read.csv(file = './data/CIP2/segment_edges.csv')
segment_edges
true_data         <- read.csv(file = './data/CIP2/true_age.csv')
good <- FALSE
bad = TRUE
repeat{
# generate some random geochronology --------------------
index <- sample(seq_along(true_data$position), size = size)
tmp   <- true_data[index, ]
id    <- paste0('sample_', index)
# check to make sure the hiatus is bracketed
# keep dates out of the hiatus
bad <- any(between(tmp$position, 5.24, 6.26))
good = any(between(tmp$position, 0, 5.24)) &
any(between(tmp$position, 6.26, 10))
if(good == TRUE) {
if(bad == FALSE) {
break()
}
}
}
size = 4
good <- FALSE
bad = TRUE
repeat{
# generate some random geochronology --------------------
index <- sample(seq_along(true_data$position), size = size)
tmp   <- true_data[index, ]
id    <- paste0('sample_', index)
# check to make sure the hiatus is bracketed
# keep dates out of the hiatus
bad <- any(between(tmp$position, 5.24, 6.26))
good = any(between(tmp$position, 0, 5.24)) &
any(between(tmp$position, 6.26, 10))
if(good == TRUE) {
if(bad == FALSE) {
break()
}
}
}
tmp
geochron_data <- data.frame(
id = id,
age = tmp$age,
age_sd =  tmp$age * 0.015,
position = tmp$position,
thickness = 0)
geochron_data
geochron_data$id
paste(geochron_data$age, sep =',')
paste(geochron_data$age, sep =,)
paste(geochron_data$age, sep =",")
geochron_data$age
geochron_data$age_sd
geochron_data$position
geochron_data$thickness
geochron_data     <- data.frame(id = c("sample_a", "sample_b",  "sample_c", "sample_d"),
age = c(0.750, 0.589, 1.421, 1.361),
age_sd = c(0.0113, 0.009, 0.0213, 0.0204),
position = c(2.70, 0.91, 8.85, 7.99),
thickness = c(0, 0, 0, 0))
geochron_data
# load the testing data on each cluster ---------------------------------------
clusterEvalQ(cl = cl, {
library(astroBayes)
library(tidyverse)
# load required data
cyclostrat        <- read.csv(file = './data/CIP2/cyclostrat_data.csv')
tuning_frequency  <- read.csv(file = './data/CIP2/tuning_frequency.csv')
true_data         <- read.csv(file = './data/CIP2/true_age.csv')
segment_edges     <-data.frame(position = c(0, 3, 5.75, 10),
thickness = c(0, 0.5, 0.5, 0),
hiatus_boundary = c(FALSE, FALSE, TRUE, FALSE),
sed_min = c(7.5, 7.5, 10, 5),
sed_max = c(15, 17.5, 20, 20))
geochron_data     <- data.frame(id        = c("sample_a", "sample_b",  "sample_c", "sample_d"),
age.      = c(0.750, 0.589, 1.421, 1.361),
age_sd    = c(0.0113, 0.009, 0.0213, 0.0204),
position  = c(2.70, 0.91, 8.85, 7.99),
thickness = c(0, 0, 0, 0))
}
)
paste('c(', geochron_data$)
rm(list = ls())
# load required libraries -----------------------------------------------------
library(parallel)
library(tidyverse)
# set up the models to test ---------------------------------------------------
iterations <- 1000 # test each set of parameters 1000 times
index    <- rep(1:iterations) # add iterations
# put it in a data frame
tests    <- data.frame(i = index)
# set up for parallel processing ----------------------------------------------
numCores <- detectCores() - 2 # leave one core to run the computer
cl <- makeCluster(numCores) # make a cluster running R in parallel
# load the testing data on each cluster ---------------------------------------
clusterEvalQ(cl = cl, {
library(astroBayes)
library(tidyverse)
# load required data
cyclostrat        <- read.csv(file = './data/CIP2/cyclostrat_data.csv')
tuning_frequency  <- read.csv(file = './data/CIP2/tuning_frequency.csv')
true_data         <- read.csv(file = './data/CIP2/true_age.csv')
segment_edges     <-data.frame(position = c(0, 3, 5.75, 10),
thickness = c(0, 0.5, 0.5, 0),
hiatus_boundary = c(FALSE, FALSE, TRUE, FALSE),
sed_min = c(7.5, 7.5, 10, 5),
sed_max = c(15, 17.5, 20, 20))
geochron_data     <- data.frame(id        = c("sample_a", "sample_b",  "sample_c", "sample_d"),
age.      = c(0.750, 0.589, 1.421, 1.361),
age_sd    = c(0.0113, 0.009, 0.0213, 0.0204),
position  = c(2.70, 0.91, 8.85, 7.99),
thickness = c(0, 0, 0, 0))
}
)
##-----------------------------------------------------------------------------
## make a function for parallel processing
age_model <- function(i) {
# generate some random geochronology --------------------
# run the model -----------------------------------------
model <- astro_bayes_model(
geochron_data = geochron_data,
cyclostrat_data = cyclostrat,
tuning_frequency = tuning_frequency,
segment_edges = segment_edges,
iterations = 10000,
burn = 1000,
method = 'malinverno')
# prep the model outputs --------------------------------
f <- approxfun(x = true_data$position, y = true_data$age)
true_age <- f(model$CI$position)
# write the model CI to a csv --------------------------
model_folder <- './results/stability_validation/CIP2/'
model_name   <- paste0('age_model_', i, '.rds')
model |>
write_rds(file = paste0(model_folder, model_name))
rm(model)
} # end of function
# run R in parallel ------------------------------------------------------------
start <- Sys.time()
clusterMap(cl = cl,
fun = age_model,
i = tests$i)
stopCluster(cl)
rm(list = ls())
# load required libraries -----------------------------------------------------
library(parallel)
library(tidyverse)
# set up the models to test ---------------------------------------------------
iterations <- 1000 # test each set of parameters 1000 times
index    <- rep(1:iterations) # add iterations
# put it in a data frame
tests    <- data.frame(i = index)
# set up for parallel processing ----------------------------------------------
numCores <- detectCores() - 2 # leave one core to run the computer
cl <- makeCluster(numCores) # make a cluster running R in parallel
# load the testing data on each cluster ---------------------------------------
clusterEvalQ(cl = cl, {
library(astroBayes)
library(tidyverse)
# load required data
cyclostrat        <- read.csv(file = './data/CIP2/cyclostrat_data.csv')
tuning_frequency  <- read.csv(file = './data/CIP2/tuning_frequency.csv')
true_data         <- read.csv(file = './data/CIP2/true_age.csv')
segment_edges     <-data.frame(position = c(0, 3, 5.75, 10),
thickness = c(0, 0.5, 0.5, 0),
hiatus_boundary = c(FALSE, FALSE, TRUE, FALSE),
sed_min = c(7.5, 7.5, 10, 5),
sed_max = c(15, 17.5, 20, 20))
geochron_data     <- data.frame(id        = c("sample_a", "sample_b",  "sample_c", "sample_d"),
age       = c(0.750, 0.589, 1.421, 1.361),
age_sd    = c(0.0113, 0.009, 0.0213, 0.0204),
position  = c(2.70, 0.91, 8.85, 7.99),
thickness = c(0, 0, 0, 0))
}
)
##-----------------------------------------------------------------------------
## make a function for parallel processing
age_model <- function(i) {
# generate some random geochronology --------------------
# run the model -----------------------------------------
model <- astro_bayes_model(
geochron_data = geochron_data,
cyclostrat_data = cyclostrat,
tuning_frequency = tuning_frequency,
segment_edges = segment_edges,
iterations = 10000,
burn = 1000,
method = 'malinverno')
# prep the model outputs --------------------------------
f <- approxfun(x = true_data$position, y = true_data$age)
true_age <- f(model$CI$position)
# write the model CI to a csv --------------------------
model_folder <- './results/stability_validation/CIP2/'
model_name   <- paste0('age_model_', i, '.rds')
model |>
write_rds(file = paste0(model_folder, model_name))
rm(model)
} # end of function
# run R in parallel ------------------------------------------------------------
start <- Sys.time()
clusterMap(cl = cl,
fun = age_model,
i = tests$i)
stopCluster(cl)
end <- Sys.time()
print(end - start)
# load required libraries -----------------------------------------------------
library(tidyverse)
library(astroBayes)
theme_set(theme_minimal())
# load all the data -----------------------------------------------------------
file_list <- list.files('./results/stability_validation/CIP2/',
full.names = TRUE,
pattern = '*.rds')
storage <- data.frame(median  = vector(length = length(file_list)),
CI_2.5  = vector(length = length(file_list)),
CI_97.5 = vector(length = length(file_list)),
delta   = vector(length = length(file_list)))
for(i in seq_along(file_list)) {
model <- read_rds(file_list[i])
hiatus_position <- model$segment_edges$position[model$segment_edges$hiatus]
storage$median[i] <- model$hiatus_durations |> median()
storage$CI_2.5[i] <- model$hiatus_durations |> quantile(prob = 0.025)
storage$CI_97.5[i] <- model$hiatus_durations |> quantile(prob = 0.975)
storage$delta[i] <- (model$geochron_data$position - hiatus_position) |>
abs() |>
min()
rm(model)
}
storage <- list()
model$hiatus_durations
model$hiatus_durations |>
as.data.frame()
model$hiatus_durations |>
as.data.frame() |> head()
# load required libraries -----------------------------------------------------
library(tidyverse)
library(astroBayes)
theme_set(theme_minimal())
# load all the data -----------------------------------------------------------
file_list <- list.files('./results/stability_validation/CIP2/',
full.names = TRUE,
pattern = '*.rds')
storage <- list()
for(i in seq_along(file_list)) {
model <- read_rds(file_list[i])
list[i] <- model$hiatus_durations |>
as.data.frame() |>
select(duration = V1) |>
add_column(iteration = i)
rm(model)
}
model$hiatus_durations |>
as.data.frame() |>
select(duration = V1)
model$hiatus_durations |>
as.data.frame() |>
select(duration = V1) |>
head()
model$hiatus_durations |>
as.data.frame() |>
select(duration = V1) |>
add_column(itteration = i)
storage <- list()
for(i in seq_along(file_list)) {
model <- read_rds(file_list[i])
storage[i] <- model$hiatus_durations |>
as.data.frame() |>
select(duration = V1) |>
add_column(itteration = i)
rm(model)
}
storage <- list()
for(i in seq_along(file_list)) {
model <- read_rds(file_list[i])
storage[i] <- model$hiatus_durations |>
as.data.frame() |>
select(duration = V1) |>
add_column(iteration = i)
rm(model)
}
storage |>
ggplot(mapping = aes(x = duration,
color = iteration))
storage <- storage |>
reduce(rbind)
storage |>
ggplot(mapping = aes(x = duration,
color = iteration)) +
geom_line(stat = 'density',
alpha = 0.1) +
scale_color_viridis()
View(storage)
storage <- list()
for(i in seq_along(file_list)) {
model <- read_rds(file_list[i])
storage[i] <- model$hiatus_durations |>
as.data.frame() |>
select(duration = V1) |>
add_column(iteration = i)
rm(model)
}
storage[1]
for(i in seq_along(file_list)) {
model <- read_rds(file_list[i])
storage[[i]] <- model$hiatus_durations |>
as.data.frame() |>
select(duration = V1) |>
add_column(iteration = i)
rm(model)
}
storage <- storage |>
reduce(rbind)
storage |>
ggplot(mapping = aes(x = duration,
color = iteration)) +
geom_line(stat = 'density',
alpha = 0.1) +
scale_color_viridis()
View(storage)
storage |>
mutate(as.character(iteration)) |>
ggplot(mapping = aes(x = duration,
color = iteration)) +
geom_line(stat = 'density',
alpha = 0.1,
show.legend = FALSE) +
scale_color_viridis()
storage |>
mutate(as.character(iteration)) |>
ggplot(mapping = aes(x = duration,
group = iteration)) +
geom_line(stat = 'density',
alpha = 0.1,
show.legend = FALSE) +
scale_color_viridis()
storage[[i]] <- model$hiatus_durations |>
?slice()
? slice
storage <- list()
storage <- list()
for(i in seq_along(file_list)) {
model <- read_rds(file_list[i])
storage[[i]] <- model$hiatus_durations |>
slice(model$burn:10000) |>
as.data.frame() |>
select(duration = V1) |>
add_column(iteration = i)
rm(model)
}
model$burn
? extract
model$hiatus_durations |>
slice(model$burn:n())
storage[[i]] <- model$hiatus_durations |>
as.data.frame() |>
slice(model$burn:n()) |>
select(duration = V1) |>
add_column(iteration = i)
for(i in seq_along(file_list)) {
model <- read_rds(file_list[i])
storage[[i]] <- model$hiatus_durations |>
as.data.frame() |>
slice(model$burn:n()) |>
select(duration = V1) |>
add_column(iteration = i)
rm(model)
}
storage <- storage |>
reduce(rbind)
storage |>
mutate(as.character(iteration)) |>
ggplot(mapping = aes(x = duration,
group = iteration)) +
geom_line(stat = 'density',
alpha = 0.1,
show.legend = FALSE) +
scale_color_viridis()
storage |>
mutate(as.character(iteration)) |>
group_by(iteration) |>
sumarize(median = median(duration))
storage |>
mutate(as.character(iteration)) |>
group_by(iteration) |>
summarize(median = median(duration))
storage |>
mutate(as.character(iteration)) |>
group_by(iteration) |>
summarize(median = n(duration))
storage |>
mutate(as.character(iteration)) |>
group_by(iteration) |>
summarize(median = n())
storage |>
mutate(as.character(iteration)) |>
group_by(iteration) |>
summarize(median = mean(duration))
model <- read_rds(file_list[i])
plot(model, type = 'age_depth')
plot(model, type = 'trace')
plot(model, type = 'periodogram')
plot(model, type = 'periodogram')
model <- read_rds(file_list[1000])
model <- read_rds(file_list[500])
plot(model, type = 'age_depth')
model <- read_rds(file_list[40])
plot(model, type = 'age_depth')
